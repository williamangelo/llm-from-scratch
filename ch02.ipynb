{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900d28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/the_verdict.txt', 'r') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee297c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478621bc",
   "metadata": {},
   "source": [
    "simple tokenization with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152519ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world! This is a test text for tokenization\"\n",
    "\n",
    "preprocessed_text = [i.strip() for i in re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text) if i.strip()]\n",
    "len(preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879dcce6",
   "metadata": {},
   "source": [
    "turn tokens into id (build vocabulary, token->id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9253a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = sorted(set(preprocessed_text)) # remove dups and sort\n",
    "vocab_size = len(all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "594a809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple dict comprehension\n",
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "len(vocab.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d3a9b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f26dfa0",
   "metadata": {},
   "source": [
    "tokenize the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71a165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__ (self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s, i in vocab.items()} # reverse vocab\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'([,.:;?_!\"()\\']|--|\\s)', r'\\1' , text) # replace spaces\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "672aca3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53, 469, 988, 296, 180, 975, 215, 989, 751, 9]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"I found the couple at tea beneath their palm-trees;\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cea0c07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I found the couple at tea beneath their palm-trees ;'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bdcf9e",
   "metadata": {},
   "source": [
    "special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b8a3f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mHello, do you like tea. is this-- a test?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mSimpleTokenizerV1.encode\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m      7\u001b[39m preprocessed = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m([,.:;?_!\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m]|--|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms)\u001b[39m\u001b[33m'\u001b[39m, text)\n\u001b[32m      8\u001b[39m preprocessed = [item.strip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item.strip()]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m ids = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[31mKeyError\u001b[39m: 'Hello'"
     ]
    }
   ],
   "source": [
    "text = \"Hello, do you like tea. is this-- a test?\"\n",
    "\n",
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac3818",
   "metadata": {},
   "source": [
    "the errow above is expected! hello does not exist in our vocab, let's improve the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a54169c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72021c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__ (self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s, i in vocab.items()} # reverse vocab\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'([,.:;?_!\"()\\']|--|\\s)', r'\\1' , text) # replace spaces\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5eb7303d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 7, 584, 999, 6, 115, 1131, 10]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "text = \"Hello, do you like tea. is this-- a test?\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235312ec",
   "metadata": {},
   "source": [
    "great! we solved the problem, unkown test is recognizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9814003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, do you like tea. is this-- a test?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c65fe3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|> , do you like tea . is this -- a <|unk|> ?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d4fa7",
   "metadata": {},
   "source": [
    "there is still another problem, decoding text returns the unkown character and the llm can't distinguish between each unknown character. we solve this with byte pair encoding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4611ebe",
   "metadata": {},
   "source": [
    "current models use byte pair encoding, llama3, gpt, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6bbf1",
   "metadata": {},
   "source": [
    "github.com/openai/gpt-2 and check sebastian book bonus material for the BPE from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f79a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec718d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65e29183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 995]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1915ad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"Hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f20dde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 11,\n",
       " 466,\n",
       " 2819,\n",
       " 588,\n",
       " 8887,\n",
       " 30,\n",
       " 220,\n",
       " 50256,\n",
       " 554,\n",
       " 262,\n",
       " 4252,\n",
       " 270,\n",
       " 8812,\n",
       " 2114,\n",
       " 1659,\n",
       " 617,\n",
       " 34680,\n",
       " 27271,\n",
       " 257,\n",
       " 7456,\n",
       " 1477,\n",
       " 2093,\n",
       " 28747,\n",
       " 292,\n",
       " 292]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do tou like tea? <|endoftext|> In the sunit terraces\"\n",
    "    \"of someunknownPlace auhshaskkkasas\"\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a957c1cf",
   "metadata": {},
   "source": [
    "changing or adding random text does not yield errors anymore!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf95bfc",
   "metadata": {},
   "source": [
    "now, data sampling! - feed parts of the text to the llm insteaf of full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a9afac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/the_verdict.txt', 'r') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "len(enc_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f55d0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:] # truncate for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a86f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "# always predict the next word\n",
    "for i in range(1, context_size + 1):\n",
    "\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f513df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/william/llm-from-scratch/.venv/lib/python3.13/site-packages/torch/_subclasses/functional_tensor.py:279: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c503385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b475866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__ (self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids [idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7aca201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_last = drop the last batch if it can't have the appropriate size\n",
    "# e.g. text has 9 tokens, batch_size is 2, 4 batches with 2 tokens\n",
    "# and 1 lonely batch of 1 token, this last batch gets dropped\n",
    "def create_dataloader_v1(\n",
    "        txt, batch_size=4, max_length=256, \n",
    "        stride=128, shuffle=True, drop_last=True, num_workers=0\n",
    "    ):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bfdd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/the_verdict.txt', 'r') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a84ab80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=4, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "857eabed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1807, 3619,  402,  271]]), tensor([[ 3619,   402,   271, 10899]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc1675",
   "metadata": {},
   "source": [
    "note: stride is by how much we move text between batches, it avoids overfitting by allowing only new tokens as inputs, e.g.\n",
    "\n",
    "\"I like dogs but also like cats too\",\n",
    "with stride1:\n",
    "\n",
    "[\"I\", \"like\", \"dogs\", \"but\"], [\"like\", \"dogs\", \"but\", \"also\"]\n",
    "\n",
    "with stride 4:\n",
    "\n",
    "[\"I\", \"like\", \"dogs\", \"but\"], [\"also\", \"like\", \"cats\", \"too\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de8e59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "540ad1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]]), tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=4, stride=4, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eed028",
   "metadata": {},
   "source": [
    "batch = input, target pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4395fa",
   "metadata": {},
   "source": [
    "now, token embeddings!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e78e94",
   "metadata": {},
   "source": [
    "we go from raw text -> tokenized text -> token ids -> embedding vectors!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1a8b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aae6878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc4909cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3374, -0.1778, -0.1690],\n",
       "        [ 0.9178,  1.5810,  1.3010],\n",
       "        [ 1.2753, -0.2010, -0.1606],\n",
       "        [-0.4015,  0.9666, -1.1481],\n",
       "        [-1.1589,  0.3255, -0.6315],\n",
       "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef720fec",
   "metadata": {},
   "source": [
    "check bonus material for difference of embedding layers and linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69fea7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2753, -0.2010, -0.1606]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.tensor([2])) # same row as the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39b0fe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2753, -0.2010, -0.1606],\n",
       "        [-0.4015,  0.9666, -1.1481],\n",
       "        [-2.8400, -0.7849, -1.4096],\n",
       "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd63b6",
   "metadata": {},
   "source": [
    "word positional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "222f9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256 # very small still even for gpt2\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2f1a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2fc6f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ids: tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "input shape torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token ids: {inputs}\")\n",
    "print(f\"input shape\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5eec3ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42a67f",
   "metadata": {},
   "source": [
    "each token id is converted to a 256 dimension vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ead0f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim) # this is actually a large layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "edff4d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "de63b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f6119375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e5841425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c12312f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f49aa1b",
   "metadata": {},
   "source": [
    "## learnings\n",
    "\n",
    "### the input pipeline:\n",
    "raw text ->\n",
    "tokenized text, text split into \"words\" or \"wokens\" ->\n",
    "token ids, building a vocabulary assinging each unique token to a unique id ->\n",
    "token embeddings, turn ids into N dimensional vectors ->\n",
    "token embedding + positional embedding (information about the position of the token in the input in order to differentiate multiple tokens in the same batch) = input embedding\n",
    "\n",
    "---\n",
    "\n",
    "byte pair encoding (BPE) is how to properly encode tokens, allowing unknown words to be properly tokenized - again, check bnus material for an implementation from scratch\n",
    "\n",
    "each input batch in training should(should?) have unique tokens in order to avoid overfitting, I thought that it was sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2de4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
